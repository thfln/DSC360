{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "413dfdf7-51b2-479f-a6c5-ec5b2eb1cc30",
   "metadata": {},
   "source": [
    "# DSC360 - Week 5 - Exercise 5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a988e93-d898-494c-a6a9-fbdc8aa73045",
   "metadata": {},
   "source": [
    "We begin the exercises this week by providing a section for attribution and description."
   ]
  },
  {
   "cell_type": "raw",
   "id": "41f69a9c-a170-4c6b-b749-84327e69cd69",
   "metadata": {},
   "source": [
    "============================================\n",
    "; Title: Exercise 5.2\n",
    "; Author: Various\n",
    "; Date: 24 September 2024\n",
    "; Modified By: Tyler Heflin\n",
    "; Description: This program demonstrates the use of Python to\n",
    "; demonstrate text features in NLP.\n",
    ";=========================================== */"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9af304-5e56-4ef9-8f79-2ff45ea665af",
   "metadata": {},
   "source": [
    "We begin by also importing any necessary libraries or files for the notebook. This library was used as there were soft warnings when running the code. This would not be done in production but was done here to assist with readability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2520c323-b7a6-4911-b1a6-02d57b806873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52890cf8-896c-4b6d-9908-42d6b75ee27f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc18fd92-ecf3-4f1d-92a2-1ef6fba68ee2",
   "metadata": {},
   "source": [
    "## Exercises 5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a582e9-2445-4fb9-949a-87d73f6db15a",
   "metadata": {},
   "source": [
    "Using the file, *twitter_sample.csv*, which can be found in the data directory in the Week 5 GitHub repository:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f81730-f934-41e9-b933-1d60c2fe5469",
   "metadata": {},
   "source": [
    "## Cleaning the \"Tweet Content\" Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cf2b45-7b31-42ab-a0c1-8a0ed6037177",
   "metadata": {},
   "source": [
    "**1. Clean the \"Tweet Content\" column by removing non-text data and stop words.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fef2355-6d41-477d-8a20-8cbb65540083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Define class for cleaning tweet content\n",
    "class TweetCleaner:\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Define function to clean tweet content\n",
    "    def clean(self, text):\n",
    "        # Remove unnecessary characters\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+|#\\S+|@\\S+', '', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r'\\W', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # Convert to lower case\n",
    "        text = text.strip().lower()\n",
    "\n",
    "        # Remove stop words\n",
    "        text = ' '.join([word for word in text.split() if word not in self.stop_words])\n",
    "        return text\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r'C:\\Users\\thefli0\\Downloads\\twitter_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86705dda-4984-49b1-b3c0-ba997f08ab77",
   "metadata": {},
   "source": [
    "a. When examining the data in the \"twitter_sample.csv\" file, characters were present (i.e., emojis, symbols, etc.) that should not be included. A class was created to assist with the removal of the non-text data and stop words. This was created as such to encapsulate the cleaning logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95be20cd-0e0d-40c9-bfb7-3c6eff5e8b8d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac22a0-a8bc-4777-a723-f4a1d9bfb9d6",
   "metadata": {},
   "source": [
    "## Building BOW and TF-IDF Vectorizer Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aac24d-d53e-4c4a-8986-83cb41e2824b",
   "metadata": {},
   "source": [
    "**2. Filtering only tweets (not re-tweets) use your class from part one of this exercise to build BOW and TF-IDF Vectorizer representations of the text; print your results. Don't overthink this, leverage what the author does in the text. *NOTE*: the CountVectorizer class in sklearn has changed slightly. You'll see in the text on page 210 that there's a function called get_feature_names(). This is now get_feature_names_out(). The TfidfVectorizer class has this same change.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "142f98fe-5e9a-414a-be20-c696883ca340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter tweets prior to cleaning\n",
    "df_filtered = df[df['Tweet Type'] == 'Tweet']\n",
    "\n",
    "# Initialize TweetCleaner class\n",
    "cleaner = TweetCleaner()\n",
    "\n",
    "# Apply cleaning function to \"Tweet Content\" column\n",
    "df_filtered['Cleaned Tweet Content'] = df_filtered['Tweet Content'].apply(cleaner.clean)\n",
    "\n",
    "# Filter empty tweets after cleaning\n",
    "df_filtered = df_filtered[df_filtered['Cleaned Tweet Content'].str.strip() != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a541e23a-d91c-430e-8850-caaf98a4f564",
   "metadata": {},
   "source": [
    "a. This code cell was developed to ensure filtering of 'Tweet Type' occurred before cleaning the 'Tweet Content'. This filtering also ensured that only original tweets (not retweets) were processed. When this initial step was not included, no content was returned. This step allowed both filtering and then application of the 'TweetCleaner' class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "143abc6a-d8a0-4df9-882a-22193b1ff4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words (BOW) representation:\n",
      "     000  000th  0303  10  118  12  2010  2019  21  210  ...  wyprodukowania  \\\n",
      "0     0      0     0   0    0   0     0     0   0    0  ...               0   \n",
      "1     0      0     1   0    1   0     0     0   0    0  ...               0   \n",
      "2     0      0     0   0    0   0     0     0   0    0  ...               0   \n",
      "3     0      0     0   0    0   0     0     0   0    0  ...               0   \n",
      "4     0      0     0   0    0   0     0     0   0    0  ...               0   \n",
      "..  ...    ...   ...  ..  ...  ..   ...   ...  ..  ...  ...             ...   \n",
      "90    0      0     0   0    0   0     0     0   0    1  ...               0   \n",
      "91    0      0     0   0    0   0     0     0   0    0  ...               0   \n",
      "92    0      0     0   0    0   0     0     0   0    0  ...               0   \n",
      "93    0      0     0   0    0   0     0     0   0    0  ...               0   \n",
      "94    0      0     0   0    0   0     0     0   0    0  ...               0   \n",
      "\n",
      "    year  years  yesterday  yet  zones  zoonosen  zu  zwierząt  że  \n",
      "0      0      0          0    0      0         0   0         0   0  \n",
      "1      0      0          0    0      0         0   0         0   0  \n",
      "2      0      0          0    0      0         0   0         0   0  \n",
      "3      0      0          0    0      0         0   0         0   0  \n",
      "4      0      0          0    0      0         0   0         0   0  \n",
      "..   ...    ...        ...  ...    ...       ...  ..       ...  ..  \n",
      "90     0      0          0    0      0         0   0         0   0  \n",
      "91     1      0          0    0      0         0   0         0   0  \n",
      "92     0      0          0    0      0         0   0         0   0  \n",
      "93     2      0          0    0      0         0   0         0   0  \n",
      "94     0      0          0    0      0         0   0         0   0  \n",
      "\n",
      "[95 rows x 723 columns]\n",
      "\n",
      "TF-IDF representation:\n",
      "     000  000th      0303   10       118   12  2010  2019   21      210  ...  \\\n",
      "0   0.0    0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  0.0  0.00000  ...   \n",
      "1   0.0    0.0  0.302482  0.0  0.302482  0.0   0.0   0.0  0.0  0.00000  ...   \n",
      "2   0.0    0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  0.0  0.00000  ...   \n",
      "3   0.0    0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  0.0  0.00000  ...   \n",
      "4   0.0    0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  0.0  0.00000  ...   \n",
      "..  ...    ...       ...  ...       ...  ...   ...   ...  ...      ...  ...   \n",
      "90  0.0    0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  0.0  0.23446  ...   \n",
      "91  0.0    0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  0.0  0.00000  ...   \n",
      "92  0.0    0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  0.0  0.00000  ...   \n",
      "93  0.0    0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  0.0  0.00000  ...   \n",
      "94  0.0    0.0  0.000000  0.0  0.000000  0.0   0.0   0.0  0.0  0.00000  ...   \n",
      "\n",
      "    wyprodukowania      year  years  yesterday  yet  zones  zoonosen   zu  \\\n",
      "0              0.0  0.000000    0.0        0.0  0.0    0.0       0.0  0.0   \n",
      "1              0.0  0.000000    0.0        0.0  0.0    0.0       0.0  0.0   \n",
      "2              0.0  0.000000    0.0        0.0  0.0    0.0       0.0  0.0   \n",
      "3              0.0  0.000000    0.0        0.0  0.0    0.0       0.0  0.0   \n",
      "4              0.0  0.000000    0.0        0.0  0.0    0.0       0.0  0.0   \n",
      "..             ...       ...    ...        ...  ...    ...       ...  ...   \n",
      "90             0.0  0.000000    0.0        0.0  0.0    0.0       0.0  0.0   \n",
      "91             0.0  0.249506    0.0        0.0  0.0    0.0       0.0  0.0   \n",
      "92             0.0  0.000000    0.0        0.0  0.0    0.0       0.0  0.0   \n",
      "93             0.0  0.370432    0.0        0.0  0.0    0.0       0.0  0.0   \n",
      "94             0.0  0.000000    0.0        0.0  0.0    0.0       0.0  0.0   \n",
      "\n",
      "    zwierząt   że  \n",
      "0        0.0  0.0  \n",
      "1        0.0  0.0  \n",
      "2        0.0  0.0  \n",
      "3        0.0  0.0  \n",
      "4        0.0  0.0  \n",
      "..       ...  ...  \n",
      "90       0.0  0.0  \n",
      "91       0.0  0.0  \n",
      "92       0.0  0.0  \n",
      "93       0.0  0.0  \n",
      "94       0.0  0.0  \n",
      "\n",
      "[95 rows x 723 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Create BOW and TF-IDF Vectorizer representations\n",
    "bow_vectorizer = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Check 'Cleaned Tweet Content' not empty\n",
    "if df_filtered['Cleaned Tweet Content'].str.strip().empty:\n",
    "    print(\"No valid content to vectorize after cleaning.\")\n",
    "else:\n",
    "    # Fit and transform filtered tweets\n",
    "    bow_matrix = bow_vectorizer.fit_transform(df_filtered['Cleaned Tweet Content'])\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df_filtered['Cleaned Tweet Content'])\n",
    "\n",
    "    # Convert to DataFrames for inspection\n",
    "    bow_df = pd.DataFrame(bow_matrix.toarray(), columns=bow_vectorizer.get_feature_names_out())\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "    # Print results\n",
    "    print(\"Bag of Words (BOW) representation:\\n\", bow_df)\n",
    "    print(\"\\nTF-IDF representation:\\n\", tfidf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9333e3e4-3394-4060-9e5b-fb5357588580",
   "metadata": {},
   "source": [
    "b. The 'sklearn' library was imported to perform vectorization. An 'if/else' function was included to ensure that filtering did not inadvertently filter erroneously. Once content was noted to be present, the BOW and TF-IDF models could be fit and transform the data into vectors. The BOW representation displays a table where each row represents a tweet and each column represents a word. This allows you to see which words are most common in each tweet and how similar tweets are in word usage. Similarly, TF-IDF displays a table where each row is a tweet and each column represents a word. The scores that are returned for this matrix reflect how important each word is in the context of the tweet and to the entire dataset. These data were then converted to pandas DataFrames for further inspection and the results were printed accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7801ee18-01c9-454d-af46-75d40ba14735",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8705a4a8-dd7f-49bb-a229-6c87d6377505",
   "metadata": {},
   "source": [
    "## Finding Document Similarity Using Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac06aa0-3550-467e-bbc6-add1c013c0ba",
   "metadata": {},
   "source": [
    "**3. Find one or more documents (each tweet is a document) that are similar to each other using Cosine Similarity; print your results. (NOTE: The lower the Cosine Similarity, the more likely the documents are similar.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a55b179-2a9d-4eeb-99a8-743281789d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix:\n",
      " Tweet Id               \"1167429261210218497\"  \"1167375334670557185\"  \\\n",
      "Tweet Id                                                              \n",
      "\"1167429261210218497\"               1.000000               0.000000   \n",
      "\"1167375334670557185\"               0.000000               1.000000   \n",
      "\"1167228285463531520\"               0.000000               0.000000   \n",
      "\"1167061075075973123\"               0.000000               0.000000   \n",
      "\"1166892836165496835\"               0.000000               0.000000   \n",
      "...                                      ...                    ...   \n",
      "\"1145799585446715394\"               0.000000               0.036298   \n",
      "\"1145685620016242688\"               0.000000               0.000000   \n",
      "\"1145672954371608576\"               0.042939               0.000000   \n",
      "\"1145637718493290497\"               0.000000               0.000000   \n",
      "\"1145609117618397184\"               0.116204               0.000000   \n",
      "\n",
      "Tweet Id               \"1167228285463531520\"  \"1167061075075973123\"  \\\n",
      "Tweet Id                                                              \n",
      "\"1167429261210218497\"               0.000000               0.000000   \n",
      "\"1167375334670557185\"               0.000000               0.000000   \n",
      "\"1167228285463531520\"               1.000000               0.000000   \n",
      "\"1167061075075973123\"               0.000000               1.000000   \n",
      "\"1166892836165496835\"               0.000000               0.000000   \n",
      "...                                      ...                    ...   \n",
      "\"1145799585446715394\"               0.000000               0.000000   \n",
      "\"1145685620016242688\"               0.000000               0.000000   \n",
      "\"1145672954371608576\"               0.000000               0.000000   \n",
      "\"1145637718493290497\"               0.134215               0.119126   \n",
      "\"1145609117618397184\"               0.000000               0.000000   \n",
      "\n",
      "Tweet Id               \"1166892836165496835\"  \"1166660764146503681\"  \\\n",
      "Tweet Id                                                              \n",
      "\"1167429261210218497\"                    0.0                    0.0   \n",
      "\"1167375334670557185\"                    0.0                    0.0   \n",
      "\"1167228285463531520\"                    0.0                    0.0   \n",
      "\"1167061075075973123\"                    0.0                    0.0   \n",
      "\"1166892836165496835\"                    1.0                    0.0   \n",
      "...                                      ...                    ...   \n",
      "\"1145799585446715394\"                    0.0                    0.0   \n",
      "\"1145685620016242688\"                    0.0                    0.0   \n",
      "\"1145672954371608576\"                    0.0                    0.0   \n",
      "\"1145637718493290497\"                    0.0                    0.0   \n",
      "\"1145609117618397184\"                    0.0                    0.0   \n",
      "\n",
      "Tweet Id               \"1166580818673901568\"  \"1166395278926196738\"  \\\n",
      "Tweet Id                                                              \n",
      "\"1167429261210218497\"                    0.0               0.000000   \n",
      "\"1167375334670557185\"                    0.0               0.000000   \n",
      "\"1167228285463531520\"                    0.0               0.000000   \n",
      "\"1167061075075973123\"                    0.0               0.000000   \n",
      "\"1166892836165496835\"                    0.0               0.000000   \n",
      "...                                      ...                    ...   \n",
      "\"1145799585446715394\"                    0.0               0.242479   \n",
      "\"1145685620016242688\"                    0.0               0.000000   \n",
      "\"1145672954371608576\"                    0.0               0.000000   \n",
      "\"1145637718493290497\"                    0.0               0.000000   \n",
      "\"1145609117618397184\"                    0.0               0.000000   \n",
      "\n",
      "Tweet Id               \"1166239727751749633\"  \"1166036628365881344\"  ...  \\\n",
      "Tweet Id                                                             ...   \n",
      "\"1167429261210218497\"                    0.0               0.000000  ...   \n",
      "\"1167375334670557185\"                    0.0               0.000000  ...   \n",
      "\"1167228285463531520\"                    0.0               0.000000  ...   \n",
      "\"1167061075075973123\"                    0.0               0.000000  ...   \n",
      "\"1166892836165496835\"                    0.0               0.000000  ...   \n",
      "...                                      ...                    ...  ...   \n",
      "\"1145799585446715394\"                    0.0               0.061244  ...   \n",
      "\"1145685620016242688\"                    0.0               0.000000  ...   \n",
      "\"1145672954371608576\"                    0.0               0.000000  ...   \n",
      "\"1145637718493290497\"                    0.0               0.000000  ...   \n",
      "\"1145609117618397184\"                    0.0               0.000000  ...   \n",
      "\n",
      "Tweet Id               \"1146756014693408769\"  \"1146338404277395456\"  \\\n",
      "Tweet Id                                                              \n",
      "\"1167429261210218497\"                    0.0               0.083980   \n",
      "\"1167375334670557185\"                    0.0               0.048639   \n",
      "\"1167228285463531520\"                    0.0               0.000000   \n",
      "\"1167061075075973123\"                    0.0               0.057173   \n",
      "\"1166892836165496835\"                    0.0               0.000000   \n",
      "...                                      ...                    ...   \n",
      "\"1145799585446715394\"                    0.0               0.048069   \n",
      "\"1145685620016242688\"                    0.0               0.000000   \n",
      "\"1145672954371608576\"                    0.0               0.000000   \n",
      "\"1145637718493290497\"                    0.0               0.000000   \n",
      "\"1145609117618397184\"                    0.0               0.000000   \n",
      "\n",
      "Tweet Id               \"1146082701021200386\"  \"1146064897215627266\"  \\\n",
      "Tweet Id                                                              \n",
      "\"1167429261210218497\"               0.000000               0.000000   \n",
      "\"1167375334670557185\"               0.000000               0.066775   \n",
      "\"1167228285463531520\"               0.180619               0.000000   \n",
      "\"1167061075075973123\"               0.160312               0.000000   \n",
      "\"1166892836165496835\"               0.000000               0.000000   \n",
      "...                                      ...                    ...   \n",
      "\"1145799585446715394\"               0.000000               0.081190   \n",
      "\"1145685620016242688\"               0.000000               0.000000   \n",
      "\"1145672954371608576\"               0.000000               0.000000   \n",
      "\"1145637718493290497\"               0.110301               0.000000   \n",
      "\"1145609117618397184\"               0.000000               0.000000   \n",
      "\n",
      "Tweet Id               \"1145996576231493632\"  \"1145799585446715394\"  \\\n",
      "Tweet Id                                                              \n",
      "\"1167429261210218497\"               0.093563               0.000000   \n",
      "\"1167375334670557185\"               0.000000               0.036298   \n",
      "\"1167228285463531520\"               0.000000               0.000000   \n",
      "\"1167061075075973123\"               0.000000               0.000000   \n",
      "\"1166892836165496835\"               0.000000               0.000000   \n",
      "...                                      ...                    ...   \n",
      "\"1145799585446715394\"               0.000000               1.000000   \n",
      "\"1145685620016242688\"               0.000000               0.000000   \n",
      "\"1145672954371608576\"               0.022311               0.000000   \n",
      "\"1145637718493290497\"               0.050918               0.000000   \n",
      "\"1145609117618397184\"               0.000000               0.000000   \n",
      "\n",
      "Tweet Id               \"1145685620016242688\"  \"1145672954371608576\"  \\\n",
      "Tweet Id                                                              \n",
      "\"1167429261210218497\"               0.000000               0.042939   \n",
      "\"1167375334670557185\"               0.000000               0.000000   \n",
      "\"1167228285463531520\"               0.000000               0.000000   \n",
      "\"1167061075075973123\"               0.000000               0.000000   \n",
      "\"1166892836165496835\"               0.000000               0.000000   \n",
      "...                                      ...                    ...   \n",
      "\"1145799585446715394\"               0.000000               0.000000   \n",
      "\"1145685620016242688\"               1.000000               0.000000   \n",
      "\"1145672954371608576\"               0.000000               1.000000   \n",
      "\"1145637718493290497\"               0.215649               0.000000   \n",
      "\"1145609117618397184\"               0.000000               0.000000   \n",
      "\n",
      "Tweet Id               \"1145637718493290497\"  \"1145609117618397184\"  \n",
      "Tweet Id                                                             \n",
      "\"1167429261210218497\"               0.000000               0.116204  \n",
      "\"1167375334670557185\"               0.000000               0.000000  \n",
      "\"1167228285463531520\"               0.134215               0.000000  \n",
      "\"1167061075075973123\"               0.119126               0.000000  \n",
      "\"1166892836165496835\"               0.000000               0.000000  \n",
      "...                                      ...                    ...  \n",
      "\"1145799585446715394\"               0.000000               0.000000  \n",
      "\"1145685620016242688\"               0.215649               0.000000  \n",
      "\"1145672954371608576\"               0.000000               0.000000  \n",
      "\"1145637718493290497\"               1.000000               0.000000  \n",
      "\"1145609117618397184\"               0.000000               1.000000  \n",
      "\n",
      "[95 rows x 95 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Cosine Similarity\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Convert DataFrame for readability\n",
    "similarity_matrix = pd.DataFrame(cosine_similarities, index=df_filtered['Tweet Id'], columns=df_filtered['Tweet Id'])\n",
    "\n",
    "# Print results\n",
    "print(\"Cosine Similarity Matrix:\\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241adf2e-f4d4-4dcc-807e-704271d59fd2",
   "metadata": {},
   "source": [
    "a. For the final step of the exercise, Cosine Similarity was imported from the 'sklearn' library. Cosine Similarity was used to compute the similarity between every pair of tweets. After the calculation for Cosine Similarity was performed, the matrix was converted to a pandas DataFrame for readability using the \"Tweet Id\". The results were returned showing the cosine similarity score between every pair of tweets. The closer to 1 a score is, the more similar the tweets are, while a score closer to 0 indicates dissimilarity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
